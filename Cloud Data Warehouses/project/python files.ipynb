{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql_tables.py\n",
    "\n",
    "\"\"\"\n",
    "This file contains all the SQL definitions and control Lists used by \"create_tables.py\" and \"etl.py\"\n",
    "\"\"\"\n",
    "\n",
    "import configparser\n",
    "\n",
    "# CONFIG\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')\n",
    "\n",
    "# DROP TABLES\n",
    "\n",
    "staging_events_table_drop = \"DROP TABLE IF EXISTS staging_events\"\n",
    "staging_songs_table_drop = \"DROP TABLE IF EXISTS staging_songs\"\n",
    "songplay_table_drop = \"DROP TABLE IF EXISTS songplays\"\n",
    "user_table_drop = \"DROP TABLE IF EXISTS users\"\n",
    "song_table_drop = \"DROP TABLE IF EXISTS songs\"\n",
    "artist_table_drop = \"DROP TABLE IF EXISTS artist\"\n",
    "time_table_drop = \"DROP TABLE IF EXISTS time\"\n",
    "\n",
    "# CREATE TABLES__________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "# STAGING table creation________________________________________\n",
    "\n",
    "staging_songs_table_create = (\"\"\"\n",
    "CREATE TABLE staging_songs \n",
    "(\n",
    "  num_songs     VARCHAR NOT NULL,\n",
    "  artist_id       VARCHAR,\n",
    "  artist_latitude        VARCHAR,\n",
    "  artist_longitude   VARCHAR,\n",
    "  artist_location      VARCHAR,\n",
    "  artist_name       VARCHAR,\n",
    "  song_id        VARCHAR,\n",
    "  title        VARCHAR, \n",
    "  duration    VARCHAR,\n",
    "  year       VARCHAR  \n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "staging_events_table_create= (\"\"\"\n",
    "CREATE TABLE staging_events \n",
    "(\n",
    "  artist     VARCHAR,\n",
    "  auth       VARCHAR,\n",
    "  firstName        VARCHAR,\n",
    "  gender   VARCHAR,\n",
    "  iteminSession      VARCHAR,\n",
    "  lastName       VARCHAR,\n",
    "  length        VARCHAR,\n",
    "  level        VARCHAR, \n",
    "  location    VARCHAR,\n",
    "  method    VARCHAR,\n",
    "  page    VARCHAR,\n",
    "  registration    VARCHAR,\n",
    "  sessionid    VARCHAR,\n",
    "  song    VARCHAR,\n",
    "  status    VARCHAR,\n",
    "  ts    VARCHAR,\n",
    "  userAgent    VARCHAR,\n",
    "  userId       VARCHAR  \n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "#Warehouse tables creation ______________________________________\n",
    "\n",
    "songplay_table_create = (\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS songplays (\n",
    "songplay_id int identity(0,1) PRIMARY KEY, \n",
    "start_time varchar, \n",
    "user_id int NOT NULL, \n",
    "song_id varchar, \n",
    "artist_id varchar, \n",
    "session_id int sortkey, \n",
    "location varchar, \n",
    "user_agent varchar,\n",
    "level varchar\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "user_table_create = (\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS users (\n",
    "user_id int not null sortkey, \n",
    "first_name varchar, \n",
    "last_name varchar, \n",
    "gender varchar, \n",
    "level varchar \n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "song_table_create = (\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS songs (\n",
    "song_id varchar not null sortkey, \n",
    "title varchar, \n",
    "artist_id varchar NOT NULL, \n",
    "year int, \n",
    "duration numeric NOT NULL \n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "artist_table_create = (\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS artists (\n",
    "artist_id varchar not null sortkey, \n",
    "name varchar, \n",
    "location varchar DEFAULT 'None', \n",
    "lattitude float DEFAULT 0, \n",
    "longitude float DEFAULT 0\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "time_table_create = (\"\"\"\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS time (\n",
    "time_id int identity(0,1) PRIMARY KEY , \n",
    "start_time TIMESTAMP not null sortkey, \n",
    "hour int,\n",
    "day int, \n",
    "week int, \n",
    "month int, \n",
    "year int, \n",
    "weekday int \n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# STAGING TABLES population _____________________________________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "# Copy Commands to populate staging tables from S3\n",
    "\n",
    "staging_events_copy = (\"\"\"\n",
    "COPY staging_events FROM {}\n",
    "    credentials 'aws_iam_role={}'\n",
    "    REGION 'us-west-2'\n",
    "    FORMAT AS JSON {};\n",
    "\"\"\").format(config['S3']['LOG_DATA'], config['IAM_ROLE']['ARN'], config['S3']['LOG_JSONPATH'])\n",
    "\n",
    "staging_songs_copy = (\"\"\"\n",
    "    COPY staging_songs FROM {}\n",
    "    credentials 'aws_iam_role={}'\n",
    "    JSON 'auto'\n",
    "    REGION 'us-west-2'\n",
    "    COMPUPDATE OFF;\n",
    "\"\"\").format(config['S3']['SONG_DATA'], config['IAM_ROLE']['ARN'])\n",
    "\n",
    " \n",
    "# WAREHOUSE TABLES population ___________________________________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "songplay_table_insert = (\"\"\"\n",
    "INSERT INTO songplays (start_time, user_id, level, song_id, artist_id, session_id, location, user_agent) \\\n",
    "SELECT \\\n",
    "TIMESTAMP WITH TIME ZONE 'epoch' + CAST(staging_events.ts AS NUMERIC) * INTERVAL '1 Second ', \\\n",
    "CAST(staging_events.userId AS INT), \\\n",
    "staging_events.level, \\\n",
    "staging_songs.song_id, \\\n",
    "staging_songs.artist_id, \\\n",
    "CAST(staging_events.sessionid AS INT), \\\n",
    "staging_events.location, \\\n",
    "staging_events.userAgent \\\n",
    "FROM staging_events join staging_songs on staging_events.artist = staging_songs.artist_name and staging_events.song = staging_songs.title \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "user_table_insert = (\"\"\"\n",
    "INSERT INTO users (user_id , first_name, last_name, gender, level) SELECT DISTINCT CAST(userId AS INT), firstName, lastName, gender, level FROM staging_events where userId != ' '; \n",
    "\"\"\")\n",
    "\n",
    "song_table_insert = (\"\"\"\n",
    "INSERT INTO songs (song_id, title, artist_id, year, duration) SELECT song_id, title, artist_id, CAST(year AS INT), CAST(duration AS NUMERIC) FROM staging_songs;\n",
    "\"\"\")\n",
    "\n",
    "artist_table_insert = (\"\"\"\n",
    "INSERT INTO artists (artist_id, name, location, lattitude, longitude) SELECT DISTINCT artist_id, artist_name, artist_location , CAST(artist_latitude AS FLOAT), CAST(artist_longitude AS FLOAT) FROM staging_songs;\n",
    "\"\"\")\n",
    "\n",
    "time_table_insert = (\"\"\"\n",
    "INSERT INTO time (start_time, hour, day, week, month, year, weekday) \\\n",
    "SELECT \\\n",
    "TIMESTAMP WITH TIME ZONE 'epoch' + CAST(ts AS NUMERIC) * INTERVAL '1 Second ' AS c_Time, \\\n",
    "extract(hr from (TIMESTAMP WITH TIME ZONE 'epoch' + CAST(ts AS NUMERIC) * INTERVAL '1 Second ')) AS c_Hour, \\\n",
    "extract(day from (TIMESTAMP WITH TIME ZONE 'epoch' + CAST(ts AS NUMERIC)  * INTERVAL '1 Second ')) AS c_Day, \\\n",
    "extract(w from (TIMESTAMP WITH TIME ZONE 'epoch' + CAST(ts AS NUMERIC)  * INTERVAL '1 Second ')) AS c_Week, \\\n",
    "extract(mon from (TIMESTAMP WITH TIME ZONE 'epoch' + CAST(ts AS NUMERIC) * INTERVAL '1 Second '))AS c_Month, \\\n",
    "extract(y from (TIMESTAMP WITH TIME ZONE 'epoch' + CAST(ts AS NUMERIC) * INTERVAL '1 Second ')) AS c_Year, \\\n",
    "extract(weekday from (TIMESTAMP WITH TIME ZONE 'epoch' + CAST(ts AS NUMERIC) * INTERVAL '1 Second ')) AS c_Weekday \\\n",
    "FROM staging_events\n",
    "\"\"\")\n",
    "\n",
    "# QUERY LISTS_____________________________________________________________________________________________________________________________________________________________________________________________________  \n",
    "\n",
    "drop_table_queries = [staging_events_table_drop, staging_songs_table_drop, songplay_table_drop, user_table_drop, song_table_drop, artist_table_drop, time_table_drop]\n",
    "create_table_queries = [staging_songs_table_create, staging_events_table_create, songplay_table_create, user_table_create, song_table_create, artist_table_create, time_table_create]\n",
    "copy_table_queries = [staging_songs_copy, staging_events_copy]\n",
    "insert_table_queries = [songplay_table_insert, artist_table_insert, user_table_insert, song_table_insert, time_table_insert]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#etl.py\n",
    "import configparser\n",
    "import psycopg2\n",
    "from sql_queries import copy_table_queries, insert_table_queries \n",
    "\n",
    "\n",
    "def load_staging_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Load data from S3 to Staging tables\n",
    "    \"\"\"\n",
    "    print('Executing Staging Tables load...')\n",
    "    for query in copy_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "    print('Loading into Staging Tables Completed...')\n",
    "\n",
    " \n",
    "def insert_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Load data from Staging tables into the Warehouse\n",
    "    \"\"\"\n",
    "    print('Populating Warehouse tables...')\n",
    "    for query in insert_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "        print('{} ..Success!'.format(query))\n",
    "    print('/n Warehouse tables populated!')\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Control function, loading data from sources to targets\n",
    "    \"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('dwh.cfg')\n",
    "\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    load_staging_tables(cur, conn)\n",
    "    insert_tables(cur, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_tables.py\n",
    "\"\"\"\n",
    "\n",
    "This function (datawarehouse.ipynb) is called by the \"datawarehouse.ipynb\" Notebook in the execution of the project.  \n",
    "The primary purpose is to create all the table objects used in the project.\n",
    "The queries run are all defined in the \"sql_queries.py\" file\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import configparser\n",
    "import psycopg2\n",
    "from sql_queries import drop_table_queries, create_table_queries \n",
    "\n",
    "\n",
    "\n",
    "print('\"create_tables\" running....\\n')\n",
    "\n",
    "def drop_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Drop all tables in the cluster associated with the project.    \n",
    "    \n",
    "    \"\"\"\n",
    "    for query in drop_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "        print('{} ran succesfully...'.format(query))\n",
    "\n",
    "\n",
    "def create_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Create all tables in the cluster associated with the project.    \n",
    "    \n",
    "    \"\"\"\n",
    "    for query in create_table_queries:\n",
    "        cur.execute(query)\n",
    "        conn.commit()\n",
    "        print('{} ran succesfully...\\n'.format(query))\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    The main function controls the creation of all the tables used for the project.     \n",
    "    \n",
    "    \"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('dwh.cfg')\n",
    "\n",
    "    conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    drop_tables(cur, conn)\n",
    "    create_tables(cur, conn)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
